{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory: c:\\Ronald\\uOttawa\\CSI 6900\\Metallic-main\\creating_metafeatures\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(\"current directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \" c:/Ronald/uOttawa/CSI 6900/Metallic-main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path = os.path.relpath(current_directory, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\..\\\\..\\\\..'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed analcatdata_authorship.arff\n",
      "cls\n",
      "0    317\n",
      "1    296\n",
      "2    173\n",
      "3     55\n",
      "Name: count, dtype: int64\n",
      "Processed analcatdata_dmft.arff\n",
      "cls\n",
      "0    155\n",
      "1    136\n",
      "2    132\n",
      "3    127\n",
      "4    124\n",
      "5    123\n",
      "Name: count, dtype: int64\n",
      "Processed bodyfat.arff\n",
      "cls\n",
      "0    128\n",
      "1    124\n",
      "Name: count, dtype: int64\n",
      "Processed chscase_geyser1.arff\n",
      "cls\n",
      "0    134\n",
      "1     88\n",
      "Name: count, dtype: int64\n",
      "Processed cloud.arff\n",
      "cls\n",
      "0    76\n",
      "1    32\n",
      "Name: count, dtype: int64\n",
      "Processed confidence.arff\n",
      "cls\n",
      "0    60\n",
      "1    12\n",
      "Name: count, dtype: int64\n",
      "Processed dataset_113_primary-tumor.arff\n",
      "cls\n",
      "0     84\n",
      "1     39\n",
      "2     29\n",
      "3     28\n",
      "4     24\n",
      "5     24\n",
      "6     20\n",
      "7     16\n",
      "8     14\n",
      "9     14\n",
      "10    10\n",
      "11     9\n",
      "12     7\n",
      "13     6\n",
      "14     6\n",
      "15     2\n",
      "16     2\n",
      "17     2\n",
      "18     1\n",
      "19     1\n",
      "20     1\n",
      "Name: count, dtype: int64\n",
      "Processed dataset_11_balance-scale.arff\n",
      "cls\n",
      "0    288\n",
      "1    288\n",
      "2     49\n",
      "Name: count, dtype: int64\n",
      "dataset_190_braziltourism.arff has missing values\n",
      "Processed dataset_190_braziltourism.arff\n",
      "cls\n",
      "0    318\n",
      "1     64\n",
      "2     16\n",
      "3      7\n",
      "4      3\n",
      "5      3\n",
      "6      1\n",
      "Name: count, dtype: int64\n",
      "dataset_194_eucalyptus.arff has missing values\n",
      "Processed dataset_194_eucalyptus.arff\n",
      "cls\n",
      "0    214\n",
      "1    180\n",
      "2    130\n",
      "3    107\n",
      "4    105\n",
      "Name: count, dtype: int64\n",
      "dataset_27_colic.arff has missing values\n",
      "Processed dataset_27_colic.arff\n",
      "cls\n",
      "0    232\n",
      "1    136\n",
      "Name: count, dtype: int64\n",
      "dataset_29_credit-a.arff has missing values\n",
      "Processed dataset_29_credit-a.arff\n",
      "cls\n",
      "0    383\n",
      "1    307\n",
      "Name: count, dtype: int64\n",
      "Processed dataset_31_credit-g.arff\n",
      "cls\n",
      "0    700\n",
      "1    300\n",
      "Name: count, dtype: int64\n",
      "Processed dataset_34_postoperative-patient-data.arff\n",
      "cls\n",
      "0    64\n",
      "1    24\n",
      "2     2\n",
      "Name: count, dtype: int64\n",
      "Processed dataset_37_diabetes.arff\n",
      "cls\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n",
      "dataset_4_labor.arff has missing values\n",
      "Processed dataset_4_labor.arff\n",
      "cls\n",
      "0    37\n",
      "1    20\n",
      "Name: count, dtype: int64\n",
      "Processed dataset_50_tic-tac-toe.arff\n",
      "cls\n",
      "0    626\n",
      "1    332\n",
      "Name: count, dtype: int64\n",
      "dataset_51_heart-h.arff has missing values\n",
      "Processed dataset_51_heart-h.arff\n",
      "cls\n",
      "0    188\n",
      "1    106\n",
      "Name: count, dtype: int64\n",
      "Processed dataset_53_heart-statlog.arff\n",
      "cls\n",
      "0    150\n",
      "1    120\n",
      "Name: count, dtype: int64\n",
      "Processed dataset_56_vote.arff\n",
      "cls\n",
      "0    267\n",
      "1    168\n",
      "Name: count, dtype: int64\n",
      "dataset_9_autos.arff has missing values\n",
      "Processed dataset_9_autos.arff\n",
      "cls\n",
      "0    67\n",
      "1    54\n",
      "2    32\n",
      "3    27\n",
      "4    22\n",
      "5     3\n",
      "Name: count, dtype: int64\n",
      "Processed fruitfly.arff\n",
      "cls\n",
      "0    76\n",
      "1    49\n",
      "Name: count, dtype: int64\n",
      "Processed kc2.arff\n",
      "cls\n",
      "0    415\n",
      "1    107\n",
      "Name: count, dtype: int64\n",
      "Processed machine_cpu.arff\n",
      "cls\n",
      "0    153\n",
      "1     56\n",
      "Name: count, dtype: int64\n",
      "Processed newton_hema.arff\n",
      "cls\n",
      "0    70\n",
      "1    70\n",
      "Name: count, dtype: int64\n",
      "Processed php0iVrYT.arff\n",
      "cls\n",
      "0    570\n",
      "1    178\n",
      "Name: count, dtype: int64\n",
      "Processed php4fATLZ.arff\n",
      "cls\n",
      "0    395\n",
      "1    206\n",
      "Name: count, dtype: int64\n",
      "Processed php5J5AK6.arff\n",
      "cls\n",
      "0    38\n",
      "1    20\n",
      "2     4\n",
      "3     1\n",
      "Name: count, dtype: int64\n",
      "Processed php5OMDBD.arff\n",
      "cls\n",
      "0     80\n",
      "1     80\n",
      "2     75\n",
      "3     75\n",
      "4     48\n",
      "5     48\n",
      "6     44\n",
      "7     44\n",
      "8     36\n",
      "9     36\n",
      "10    30\n",
      "11    30\n",
      "12    29\n",
      "13    29\n",
      "14    29\n",
      "15    29\n",
      "16    29\n",
      "17    29\n",
      "18    27\n",
      "19    27\n",
      "20    24\n",
      "21    24\n",
      "22    17\n",
      "23    17\n",
      "24    17\n",
      "25    17\n",
      "26     9\n",
      "27     9\n",
      "28     6\n",
      "29     6\n",
      "Name: count, dtype: int64\n",
      "Processed php8Mz7BG.arff\n",
      "cls\n",
      "0    3818\n",
      "1    1586\n",
      "Name: count, dtype: int64\n",
      "Processed phpAmSP4g.arff\n",
      "cls\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "phpAz9Len.arff has missing values\n",
      "Processed phpAz9Len.arff\n",
      "cls\n",
      "0    312\n",
      "1    228\n",
      "Name: count, dtype: int64\n",
      "Processed phpcFPMhq.arff\n",
      "cls\n",
      "0    290\n",
      "1    210\n",
      "Name: count, dtype: int64\n",
      "Processed phpdReP6S.arff\n",
      "cls\n",
      "0    2374\n",
      "1     160\n",
      "Name: count, dtype: int64\n",
      "Processed phpelnJ6y.arff\n",
      "cls\n",
      "0    383\n",
      "1    307\n",
      "Name: count, dtype: int64\n",
      "phpH2fvsy.arff has missing values\n",
      "Processed phpH2fvsy.arff\n",
      "cls\n",
      "0    23\n",
      "1    21\n",
      "2     8\n",
      "Name: count, dtype: int64\n",
      "Processed phphZierv.arff\n",
      "cls\n",
      "0    288\n",
      "1    266\n",
      "Name: count, dtype: int64\n",
      "Processed phpnYQXoc.arff\n",
      "cls\n",
      "0    49\n",
      "1    46\n",
      "2    41\n",
      "3    19\n",
      "Name: count, dtype: int64\n",
      "Processed phpSF8oeR.arff\n",
      "cls\n",
      "0    12\n",
      "1    12\n",
      "2    12\n",
      "Name: count, dtype: int64\n",
      "Processed phpSj3fWL.arff\n",
      "cls\n",
      "0    57\n",
      "1    57\n",
      "2    53\n",
      "3    52\n",
      "4    52\n",
      "5    51\n",
      "6    49\n",
      "7    47\n",
      "8    45\n",
      "9    37\n",
      "Name: count, dtype: int64\n",
      "phpu00N5N.arff has missing values\n",
      "Processed phpu00N5N.arff\n",
      "cls\n",
      "0    24\n",
      "1    24\n",
      "2     4\n",
      "Name: count, dtype: int64\n",
      "Processed phpui3LSc.arff\n",
      "cls\n",
      "0    140\n",
      "1    140\n",
      "2    140\n",
      "3    140\n",
      "4    133\n",
      "5    133\n",
      "6    119\n",
      "Name: count, dtype: int64\n",
      "Processed phputZAUn.arff\n",
      "cls\n",
      "0    165\n",
      "1    149\n",
      "2     89\n",
      "3     78\n",
      "4     73\n",
      "5     73\n",
      "6     66\n",
      "7     57\n",
      "Name: count, dtype: int64\n",
      "Processed phpXeun7q.arff\n",
      "cls\n",
      "0    494\n",
      "1     46\n",
      "Name: count, dtype: int64\n",
      "Processed plasma_retinol.arff\n",
      "cls\n",
      "0    182\n",
      "1    133\n",
      "Name: count, dtype: int64\n",
      "Processed pollution.arff\n",
      "cls\n",
      "0    31\n",
      "1    29\n",
      "Name: count, dtype: int64\n",
      "Processed profb.arff\n",
      "cls\n",
      "0    448\n",
      "1    224\n",
      "Name: count, dtype: int64\n",
      "Processed rabe_266.arff\n",
      "cls\n",
      "0    63\n",
      "1    57\n",
      "Name: count, dtype: int64\n",
      "Processed servo.arff\n",
      "cls\n",
      "0    129\n",
      "1     38\n",
      "Name: count, dtype: int64\n",
      "Processed sleuth_case2002.arff\n",
      "cls\n",
      "0    78\n",
      "1    69\n",
      "Name: count, dtype: int64\n",
      "Processed synthetic_control.arff\n",
      "cls\n",
      "0    100\n",
      "1    100\n",
      "2    100\n",
      "3    100\n",
      "4    100\n",
      "5    100\n",
      "Name: count, dtype: int64\n",
      "Processed transplant.arff\n",
      "cls\n",
      "0    83\n",
      "1    48\n",
      "Name: count, dtype: int64\n",
      "Processed veteran.arff\n",
      "cls\n",
      "0    94\n",
      "1    43\n",
      "Name: count, dtype: int64\n",
      "Processed visualizing_environmental.arff\n",
      "cls\n",
      "0    58\n",
      "1    53\n",
      "Name: count, dtype: int64\n",
      "Processed visualizing_galaxy.arff\n",
      "cls\n",
      "0    175\n",
      "1    148\n",
      "Name: count, dtype: int64\n",
      "Processed visualizing_livestock.arff\n",
      "cls\n",
      "0    105\n",
      "1     25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "source_directory = './additional_dataset/'\n",
    "target_directory = './processed_dataset/'\n",
    "\n",
    "\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "\n",
    "for filename in os.listdir(source_directory):\n",
    "    if filename.endswith('.arff'):\n",
    "\n",
    "        file_path = os.path.join(source_directory, filename)\n",
    "        target_file_path = os.path.join(target_directory, filename.replace('.arff', '.csv'))\n",
    "\n",
    " \n",
    "        data, _ = arff.loadarff(file_path)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        substrings_to_remove = ['year', 'month', 'number', 'id', 'timestamp', 'index', 'text', 'period', 'counter']\n",
    "        df.drop(columns=[col for col in df.columns if any(substring in col.lower() for substring in substrings_to_remove)], inplace=True, errors='ignore')\n",
    "\n",
    "        # remove 'b' and ' ' in original dataset\n",
    "        # df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "        df = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "        # missing values\n",
    "        if df.isnull().values.any():\n",
    "            print(f\"{filename} has missing values\")\n",
    "            for column in df.columns:\n",
    "                if df[column].dtype == 'object':\n",
    "                    # mode for categorical variables\n",
    "                    most_common = df[column].mode()[0]\n",
    "                    df[column].fillna(most_common, inplace=True)\n",
    "                else:\n",
    "                    # mean for numeric variables\n",
    "                    mean_value = df[column].mean()\n",
    "                    df[column].fillna(mean_value, inplace=True)\n",
    "                    df[column] = df[column].round(1)\n",
    "\n",
    "        # If target column is not the last column, move to the last\n",
    "        class_column = None\n",
    "        for col in df.columns:\n",
    "            if 'class' in col.lower() or col == 'Home/Away' in col:\n",
    "                class_column = col\n",
    "                break\n",
    "        if class_column and df.columns[-1] != class_column:\n",
    "            class_col = df[class_column]\n",
    "            df = df.drop(columns=[class_column])\n",
    "            df['cls'] = class_col\n",
    "        else:\n",
    "            df.rename(columns={df.columns[-1]: 'cls'}, inplace=True)\n",
    "        \n",
    "\n",
    "        # Assign numeric labels based on class frequency\n",
    "        class_counts = df['cls'].value_counts(ascending=False)\n",
    "        class_mapping = {cls: i for i, cls in enumerate(class_counts.index)}\n",
    "        df['cls'] = df['cls'].map(class_mapping)\n",
    "\n",
    "        \n",
    "        label_encoders = {}\n",
    "        for column in df.columns:\n",
    "            if df[column].dtype == 'object':\n",
    "                le = LabelEncoder()\n",
    "                df[column] = le.fit_transform(df[column])\n",
    "                label_encoders[column] = le\n",
    "\n",
    "\n",
    "        df.to_csv(target_file_path, index=False)\n",
    "\n",
    "        print(f\"Processed {filename}\")\n",
    "        print(df['cls'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: analcatdata_authorship.csv\n",
      "Rows: 841\n",
      "Features: 69\n",
      "Classes: 4\n",
      "Minority Cases: 55\n",
      "Imbalance Ratio: 5.76\n",
      "\n",
      "Dataset: analcatdata_dmft.csv\n",
      "Rows: 797\n",
      "Features: 4\n",
      "Classes: 6\n",
      "Minority Cases: 123\n",
      "Imbalance Ratio: 1.26\n",
      "\n",
      "Dataset: Australian.csv\n",
      "Rows: 690\n",
      "Features: 14\n",
      "Classes: 2\n",
      "Minority Cases: 307\n",
      "Imbalance Ratio: 1.25\n",
      "\n",
      "Dataset: autos.csv\n",
      "Rows: 205\n",
      "Features: 24\n",
      "Classes: 6\n",
      "Minority Cases: 3\n",
      "Imbalance Ratio: 22.33\n",
      "\n",
      "Dataset: autoUniv-au6-750.csv\n",
      "Rows: 750\n",
      "Features: 40\n",
      "Classes: 8\n",
      "Minority Cases: 57\n",
      "Imbalance Ratio: 2.89\n",
      "\n",
      "Dataset: balance-scale.csv\n",
      "Rows: 625\n",
      "Features: 4\n",
      "Classes: 3\n",
      "Minority Cases: 49\n",
      "Imbalance Ratio: 5.88\n",
      "\n",
      "Dataset: blood-transfusion-service-center.csv\n",
      "Rows: 748\n",
      "Features: 4\n",
      "Classes: 2\n",
      "Minority Cases: 178\n",
      "Imbalance Ratio: 3.20\n",
      "\n",
      "Dataset: bodyfat.csv\n",
      "Rows: 252\n",
      "Features: 14\n",
      "Classes: 2\n",
      "Minority Cases: 124\n",
      "Imbalance Ratio: 1.03\n",
      "\n",
      "Dataset: braziltourism.csv\n",
      "Rows: 412\n",
      "Features: 8\n",
      "Classes: 7\n",
      "Minority Cases: 1\n",
      "Imbalance Ratio: 318.00\n",
      "\n",
      "Dataset: chscase_geyser1.csv\n",
      "Rows: 222\n",
      "Features: 2\n",
      "Classes: 2\n",
      "Minority Cases: 88\n",
      "Imbalance Ratio: 1.52\n",
      "\n",
      "Dataset: climate-model-simulation-crashes.csv\n",
      "Rows: 540\n",
      "Features: 20\n",
      "Classes: 2\n",
      "Minority Cases: 46\n",
      "Imbalance Ratio: 10.74\n",
      "\n",
      "Dataset: cloud.csv\n",
      "Rows: 108\n",
      "Features: 6\n",
      "Classes: 2\n",
      "Minority Cases: 32\n",
      "Imbalance Ratio: 2.38\n",
      "\n",
      "Dataset: colic.csv\n",
      "Rows: 368\n",
      "Features: 22\n",
      "Classes: 2\n",
      "Minority Cases: 136\n",
      "Imbalance Ratio: 1.71\n",
      "\n",
      "Dataset: collins.csv\n",
      "Rows: 1000\n",
      "Features: 19\n",
      "Classes: 30\n",
      "Minority Cases: 6\n",
      "Imbalance Ratio: 13.33\n",
      "\n",
      "Dataset: confidence.csv\n",
      "Rows: 72\n",
      "Features: 3\n",
      "Classes: 2\n",
      "Minority Cases: 12\n",
      "Imbalance Ratio: 5.00\n",
      "\n",
      "Dataset: credit-a.csv\n",
      "Rows: 690\n",
      "Features: 15\n",
      "Classes: 2\n",
      "Minority Cases: 307\n",
      "Imbalance Ratio: 1.25\n",
      "\n",
      "Dataset: credit-g.csv\n",
      "Rows: 1000\n",
      "Features: 19\n",
      "Classes: 2\n",
      "Minority Cases: 300\n",
      "Imbalance Ratio: 2.33\n",
      "\n",
      "Dataset: cylinder-bands.csv\n",
      "Rows: 540\n",
      "Features: 35\n",
      "Classes: 2\n",
      "Minority Cases: 228\n",
      "Imbalance Ratio: 1.37\n",
      "\n",
      "Dataset: diabetes.csv\n",
      "Rows: 768\n",
      "Features: 8\n",
      "Classes: 2\n",
      "Minority Cases: 268\n",
      "Imbalance Ratio: 1.87\n",
      "\n",
      "Dataset: dresses-sales.csv\n",
      "Rows: 500\n",
      "Features: 12\n",
      "Classes: 2\n",
      "Minority Cases: 210\n",
      "Imbalance Ratio: 1.38\n",
      "\n",
      "Dataset: eating.csv\n",
      "Rows: 945\n",
      "Features: 6203\n",
      "Classes: 7\n",
      "Minority Cases: 119\n",
      "Imbalance Ratio: 1.18\n",
      "\n",
      "Dataset: eucalyptus.csv\n",
      "Rows: 736\n",
      "Features: 18\n",
      "Classes: 5\n",
      "Minority Cases: 105\n",
      "Imbalance Ratio: 2.04\n",
      "\n",
      "Dataset: fruitfly.csv\n",
      "Rows: 125\n",
      "Features: 4\n",
      "Classes: 2\n",
      "Minority Cases: 49\n",
      "Imbalance Ratio: 1.55\n",
      "\n",
      "Dataset: grub-damage.csv\n",
      "Rows: 155\n",
      "Features: 6\n",
      "Classes: 4\n",
      "Minority Cases: 19\n",
      "Imbalance Ratio: 2.58\n",
      "\n",
      "Dataset: heart-h.csv\n",
      "Rows: 294\n",
      "Features: 13\n",
      "Classes: 2\n",
      "Minority Cases: 106\n",
      "Imbalance Ratio: 1.77\n",
      "\n",
      "Dataset: heart-statlog.csv\n",
      "Rows: 270\n",
      "Features: 12\n",
      "Classes: 2\n",
      "Minority Cases: 120\n",
      "Imbalance Ratio: 1.25\n",
      "\n",
      "Dataset: kc2.csv\n",
      "Rows: 522\n",
      "Features: 21\n",
      "Classes: 2\n",
      "Minority Cases: 107\n",
      "Imbalance Ratio: 3.88\n",
      "\n",
      "Dataset: labor.csv\n",
      "Rows: 57\n",
      "Features: 12\n",
      "Classes: 2\n",
      "Minority Cases: 20\n",
      "Imbalance Ratio: 1.85\n",
      "\n",
      "Dataset: LED-display-domain-7digit.csv\n",
      "Rows: 500\n",
      "Features: 7\n",
      "Classes: 10\n",
      "Minority Cases: 37\n",
      "Imbalance Ratio: 1.54\n",
      "\n",
      "Dataset: machine_cpu.csv\n",
      "Rows: 209\n",
      "Features: 6\n",
      "Classes: 2\n",
      "Minority Cases: 56\n",
      "Imbalance Ratio: 2.73\n",
      "\n",
      "Dataset: monks-problems-2.csv\n",
      "Rows: 601\n",
      "Features: 6\n",
      "Classes: 2\n",
      "Minority Cases: 206\n",
      "Imbalance Ratio: 1.92\n",
      "\n",
      "Dataset: monks-problems-3.csv\n",
      "Rows: 554\n",
      "Features: 6\n",
      "Classes: 2\n",
      "Minority Cases: 266\n",
      "Imbalance Ratio: 1.08\n",
      "\n",
      "Dataset: newton_hema.csv\n",
      "Rows: 140\n",
      "Features: 2\n",
      "Classes: 2\n",
      "Minority Cases: 70\n",
      "Imbalance Ratio: 1.00\n",
      "\n",
      "Dataset: ozone-level-8hr.csv\n",
      "Rows: 2534\n",
      "Features: 72\n",
      "Classes: 2\n",
      "Minority Cases: 160\n",
      "Imbalance Ratio: 14.84\n",
      "\n",
      "Dataset: pasture.csv\n",
      "Rows: 36\n",
      "Features: 22\n",
      "Classes: 3\n",
      "Minority Cases: 12\n",
      "Imbalance Ratio: 1.00\n",
      "\n",
      "Dataset: phoneme.csv\n",
      "Rows: 5404\n",
      "Features: 5\n",
      "Classes: 2\n",
      "Minority Cases: 1586\n",
      "Imbalance Ratio: 2.41\n",
      "\n",
      "Dataset: plasma_retinol.csv\n",
      "Rows: 315\n",
      "Features: 13\n",
      "Classes: 2\n",
      "Minority Cases: 133\n",
      "Imbalance Ratio: 1.37\n",
      "\n",
      "Dataset: pollution.csv\n",
      "Rows: 60\n",
      "Features: 14\n",
      "Classes: 2\n",
      "Minority Cases: 29\n",
      "Imbalance Ratio: 1.07\n",
      "\n",
      "Dataset: postoperative-patient-data.csv\n",
      "Rows: 90\n",
      "Features: 8\n",
      "Classes: 3\n",
      "Minority Cases: 2\n",
      "Imbalance Ratio: 32.00\n",
      "\n",
      "Dataset: primary-tumor.csv\n",
      "Rows: 339\n",
      "Features: 17\n",
      "Classes: 21\n",
      "Minority Cases: 1\n",
      "Imbalance Ratio: 84.00\n",
      "\n",
      "Dataset: profb.csv\n",
      "Rows: 672\n",
      "Features: 8\n",
      "Classes: 2\n",
      "Minority Cases: 224\n",
      "Imbalance Ratio: 2.00\n",
      "\n",
      "Dataset: rabe_266.csv\n",
      "Rows: 120\n",
      "Features: 2\n",
      "Classes: 2\n",
      "Minority Cases: 57\n",
      "Imbalance Ratio: 1.11\n",
      "\n",
      "Dataset: servo.csv\n",
      "Rows: 167\n",
      "Features: 4\n",
      "Classes: 2\n",
      "Minority Cases: 38\n",
      "Imbalance Ratio: 3.39\n",
      "\n",
      "Dataset: sleuth_case2002.csv\n",
      "Rows: 147\n",
      "Features: 6\n",
      "Classes: 2\n",
      "Minority Cases: 69\n",
      "Imbalance Ratio: 1.13\n",
      "\n",
      "Dataset: squash-stored.csv\n",
      "Rows: 52\n",
      "Features: 23\n",
      "Classes: 3\n",
      "Minority Cases: 8\n",
      "Imbalance Ratio: 2.88\n",
      "\n",
      "Dataset: squash-unstored.csv\n",
      "Rows: 52\n",
      "Features: 22\n",
      "Classes: 3\n",
      "Minority Cases: 4\n",
      "Imbalance Ratio: 6.00\n",
      "\n",
      "Dataset: synthetic_control.csv\n",
      "Rows: 600\n",
      "Features: 60\n",
      "Classes: 6\n",
      "Minority Cases: 100\n",
      "Imbalance Ratio: 1.00\n",
      "\n",
      "Dataset: tic-tac-toe.csv\n",
      "Rows: 958\n",
      "Features: 4\n",
      "Classes: 2\n",
      "Minority Cases: 332\n",
      "Imbalance Ratio: 1.89\n",
      "\n",
      "Dataset: transplant.csv\n",
      "Rows: 131\n",
      "Features: 3\n",
      "Classes: 2\n",
      "Minority Cases: 48\n",
      "Imbalance Ratio: 1.73\n",
      "\n",
      "Dataset: veteran.csv\n",
      "Rows: 137\n",
      "Features: 6\n",
      "Classes: 2\n",
      "Minority Cases: 43\n",
      "Imbalance Ratio: 2.19\n",
      "\n",
      "Dataset: visualizing_environmental.csv\n",
      "Rows: 111\n",
      "Features: 3\n",
      "Classes: 2\n",
      "Minority Cases: 53\n",
      "Imbalance Ratio: 1.09\n",
      "\n",
      "Dataset: visualizing_galaxy.csv\n",
      "Rows: 323\n",
      "Features: 4\n",
      "Classes: 2\n",
      "Minority Cases: 148\n",
      "Imbalance Ratio: 1.18\n",
      "\n",
      "Dataset: visualizing_livestock.csv\n",
      "Rows: 130\n",
      "Features: 2\n",
      "Classes: 2\n",
      "Minority Cases: 25\n",
      "Imbalance Ratio: 4.20\n",
      "\n",
      "Dataset: vote.csv\n",
      "Rows: 435\n",
      "Features: 14\n",
      "Classes: 2\n",
      "Minority Cases: 168\n",
      "Imbalance Ratio: 1.59\n",
      "\n",
      "Dataset: wdbc.csv\n",
      "Rows: 569\n",
      "Features: 30\n",
      "Classes: 2\n",
      "Minority Cases: 212\n",
      "Imbalance Ratio: 1.68\n",
      "\n",
      "Dataset: white-clover.csv\n",
      "Rows: 63\n",
      "Features: 31\n",
      "Classes: 4\n",
      "Minority Cases: 1\n",
      "Imbalance Ratio: 38.00\n",
      "\n",
      "Rows: Min=36, Max=5404, Median=353.5, Mean=530.02, Std=770.01\n",
      "Features: Min=2, Max=6203, Median=12.0, Mean=125.55, Std=819.62\n",
      "Classes: Min=2, Max=30, Median=2.0, Mean=3.73, Std=4.63\n",
      "Minority Cases: Min=1, Max=1586, Median=69.5, Mean=129.70, Std=216.92\n",
      "Imbalance Ratio: Min=1.00, Max=318.00, Median=1.88, Mean=11.37, Std=43.25\n"
     ]
    }
   ],
   "source": [
    "target_directory = './processed_dataset/'\n",
    "\n",
    "rows_list = []\n",
    "features_list = []\n",
    "classes_list = []\n",
    "minority_cases_list = []\n",
    "imbalance_ratio_list = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(target_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(target_directory, filename)\n",
    "\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        num_rows = len(df)\n",
    "        num_features = len(df.columns) - 1  \n",
    "        num_classes = len(df.iloc[:, -1].unique())\n",
    "        class_counts = df.iloc[:, -1].value_counts()\n",
    "        minority_cases = class_counts.min()\n",
    "        imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "\n",
    "\n",
    "        rows_list.append(num_rows)\n",
    "        features_list.append(num_features)\n",
    "        classes_list.append(num_classes)\n",
    "        minority_cases_list.append(minority_cases)\n",
    "        imbalance_ratio_list.append(imbalance_ratio)\n",
    "\n",
    "\n",
    "        print(f\"Dataset: {filename}\")\n",
    "        print(f\"Rows: {num_rows}\")\n",
    "        print(f\"Features: {num_features}\")\n",
    "        print(f\"Classes: {num_classes}\")\n",
    "        print(f\"Minority Cases: {minority_cases}\")\n",
    "        print(f\"Imbalance Ratio: {imbalance_ratio:.2f}\\n\")\n",
    "\n",
    "\n",
    "def calculate_statistics(data_list):\n",
    "    return np.min(data_list), np.max(data_list), np.median(data_list), np.mean(data_list), np.std(data_list)\n",
    "\n",
    "rows_stats = calculate_statistics(rows_list)\n",
    "features_stats = calculate_statistics(features_list)\n",
    "classes_stats = calculate_statistics(classes_list)\n",
    "minority_cases_stats = calculate_statistics(minority_cases_list)\n",
    "imbalance_ratio_stats = calculate_statistics(imbalance_ratio_list)\n",
    "\n",
    "print(f\"Rows: Min={rows_stats[0]}, Max={rows_stats[1]}, Median={rows_stats[2]}, Mean={rows_stats[3]:.2f}, Std={rows_stats[4]:.2f}\")\n",
    "print(f\"Features: Min={features_stats[0]}, Max={features_stats[1]}, Median={features_stats[2]}, Mean={features_stats[3]:.2f}, Std={features_stats[4]:.2f}\")\n",
    "print(f\"Classes: Min={classes_stats[0]}, Max={classes_stats[1]}, Median={classes_stats[2]}, Mean={classes_stats[3]:.2f}, Std={classes_stats[4]:.2f}\")\n",
    "print(f\"Minority Cases: Min={minority_cases_stats[0]}, Max={minority_cases_stats[1]}, Median={minority_cases_stats[2]}, Mean={minority_cases_stats[3]:.2f}, Std={minority_cases_stats[4]:.2f}\")\n",
    "print(f\"Imbalance Ratio: Min={imbalance_ratio_stats[0]:.2f}, Max={imbalance_ratio_stats[1]:.2f}, Median={imbalance_ratio_stats[2]:.2f}, Mean={imbalance_ratio_stats[3]:.2f}, Std={imbalance_ratio_stats[4]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed hill-valley.arff\n",
      "cls\n",
      "0    606\n",
      "1    606\n",
      "Name: count, dtype: int64\n",
      "Processed steel-plates-fault.arff\n",
      "cls\n",
      "0    1268\n",
      "1     673\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "source_directory = './test_dataset/'\n",
    "target_directory = './test_dataset/'\n",
    "\n",
    "\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "\n",
    "for filename in os.listdir(source_directory):\n",
    "    if filename.endswith('.arff'):\n",
    "\n",
    "        file_path = os.path.join(source_directory, filename)\n",
    "        target_file_path = os.path.join(target_directory, filename.replace('.arff', '.csv'))\n",
    "\n",
    " \n",
    "        data, _ = arff.loadarff(file_path)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        substrings_to_remove = ['year', 'month', 'number', 'id', 'timestamp', 'index', 'text', 'period', 'counter']\n",
    "        df.drop(columns=[col for col in df.columns if any(substring in col.lower() for substring in substrings_to_remove)], inplace=True, errors='ignore')\n",
    "\n",
    "        # remove 'b' and ' ' in original dataset\n",
    "        # df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "        df = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "        # missing values\n",
    "        if df.isnull().values.any():\n",
    "            print(f\"{filename} has missing values\")\n",
    "            for column in df.columns:\n",
    "                if df[column].dtype == 'object':\n",
    "                    # mode for categorical variables\n",
    "                    most_common = df[column].mode()[0]\n",
    "                    df[column].fillna(most_common, inplace=True)\n",
    "                else:\n",
    "                    # mean for numeric variables\n",
    "                    mean_value = df[column].mean()\n",
    "                    df[column].fillna(mean_value, inplace=True)\n",
    "                    df[column] = df[column].round(1)\n",
    "\n",
    "        # If target column is not the last column, move to the last\n",
    "        class_column = None\n",
    "        for col in df.columns:\n",
    "            if 'class' in col.lower() or col == 'Home/Away' in col:\n",
    "                class_column = col\n",
    "                break\n",
    "        if class_column and df.columns[-1] != class_column:\n",
    "            class_col = df[class_column]\n",
    "            df = df.drop(columns=[class_column])\n",
    "            df['cls'] = class_col\n",
    "        else:\n",
    "            df.rename(columns={df.columns[-1]: 'cls'}, inplace=True)\n",
    "        \n",
    "\n",
    "        # Assign numeric labels based on class frequency\n",
    "        class_counts = df['cls'].value_counts(ascending=False)\n",
    "        class_mapping = {cls: i for i, cls in enumerate(class_counts.index)}\n",
    "        df['cls'] = df['cls'].map(class_mapping)\n",
    "\n",
    "        \n",
    "        label_encoders = {}\n",
    "        for column in df.columns:\n",
    "            if df[column].dtype == 'object':\n",
    "                le = LabelEncoder()\n",
    "                df[column] = le.fit_transform(df[column])\n",
    "                label_encoders[column] = le\n",
    "\n",
    "\n",
    "        df.to_csv(target_file_path, index=False)\n",
    "\n",
    "        print(f\"Processed {filename}\")\n",
    "        print(df['cls'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a75b28f9753f4e2f1476ae5e5ad4b4ab71094e0d64ff40d9df34ddf691f3c573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
